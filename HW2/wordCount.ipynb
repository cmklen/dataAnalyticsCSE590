{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CSE 590 Assignment \\#2 \r\n",
    "\r\n",
    "## Parts A & B\r\n",
    "a.) The text for this project is \"The Princess and the Goblin\"\r\n",
    "b.) The words are placed in sequential order into the variable `wordListInOrder`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\r\n",
    "import pandas as pd \r\n",
    "\r\n",
    "wordListInOrder = []\r\n",
    "ignoreChapterNum = False\r\n",
    "\r\n",
    "#helper function to remove special characters from words\r\n",
    "def filterUnwantedCharacters(word):\r\n",
    "    return re.sub('[!@#$.,?\\';]', '', word)\r\n",
    "\r\n",
    "def addWordOnly(wordList, word):\r\n",
    "    #double dash is Em dash and actually two seperate words\r\n",
    "    if \"--\" in word:\r\n",
    "        hyphenedWords = word.split(\"--\")\r\n",
    "        wordList.append(filterUnwantedCharacters(hyphenedWords[0]))\r\n",
    "        wordList.append(filterUnwantedCharacters(hyphenedWords[1]))\r\n",
    "    else:\r\n",
    "        wordList.append(filterUnwantedCharacters(word))\r\n",
    "\r\n",
    "with open('princessAndGoblin.txt', 'r') as file:\r\n",
    "    for line in file:\r\n",
    "        for word in line.split():\r\n",
    "            #if last word was a chapter, ignore the number\r\n",
    "            if ignoreChapterNum:\r\n",
    "                ignoreChapterNum = False\r\n",
    "                continue\r\n",
    "\r\n",
    "            if word == \"CHAPTER\":\r\n",
    "                ignoreChapterNum = True\r\n",
    "                continue\r\n",
    "\r\n",
    "            addWordOnly(wordListInOrder, word)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "c.) `df` is the variable used for the data frame for part c. To convert the list to a dataframe, an intermediate step of converting to a dictionary is used. This is to help count the instances of unique words."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "wordCounts = {}\r\n",
    "\r\n",
    "#convert list to dict for easy counting\r\n",
    "for word in wordListInOrder:\r\n",
    "    if word.lower() in wordCounts:\r\n",
    "        wordCounts[word.lower()][0] += 1\r\n",
    "    else:\r\n",
    "        wordCounts[word.lower()] = [1]\r\n",
    "\r\n",
    "df = pd.DataFrame.from_dict(wordCounts, orient='index')\r\n",
    "df.columns = ['Count']\r\n",
    "\r\n",
    "print(df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           Count\n",
      "why           60\n",
      "the         3202\n",
      "princess     259\n",
      "has           29\n",
      "a           1006\n",
      "...          ...\n",
      "skulls         1\n",
      "softer         1\n",
      "degrees        1\n",
      "merciless      1\n",
      "volume         1\n",
      "\n",
      "[4124 rows x 1 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "d.) `dfStopWordsSorted` contains the desired output for part d. It is first copied from the dataframe in part c, then the .drop and .sort_values methods are used to arrange and condense the dataframe into the desired format."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "stopWords = [\"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"A\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appreciate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"arise\", \"around\", \"as\", \"aside\", \"ask\", \"asking\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"B\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"been\", \"before\", \"beforehand\", \"beginnings\", \"behind\", \"below\", \"beside\", \"besides\", \"best\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"C\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"could\", \"couldn\", \"couldnt\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"ct\", \"cu\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"D\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doing\", \"don\", \"done\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"E\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"F\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"G\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"H\", \"h2\", \"h3\", \"had\", \"hadn\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"have\", \"haven\", \"having\", \"he\", \"hed\", \"hello\", \"help\", \"hence\", \"here\", \"his\",\"her\",\"him\",\"she\",\"they\",\"them\",\"hereafter\", \"hereby\", \"herein\", \"heres\", \"hereupon\", \"hes\", \"hh\", \"hi\", \"hid\", \"hither\", \"hj\", \"ho\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"i\",\"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"im\", \"immediately\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"it\", \"itd\", \"its\", \"iv\", \"ix\", \"iy\", \"iz\", \"j\", \"J\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"K\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"ko\", \"l\", \"L\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"M\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"my\", \"n\", \"N\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"neither\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"O\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"otherwise\", \"ou\", \"ought\", \"our\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"P\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"Q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"R\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"S\", \"s2\", \"sa\", \"said\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"sent\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shed\", \"shes\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somehow\", \"somethan\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"sz\", \"t\", \"T\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"thereof\", \"therere\", \"theres\", \"thereto\", \"thereupon\", \"these\", \"they\", \"theyd\", \"theyre\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"U\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"using\", \"usually\", \"ut\", \"v\", \"V\", \"va\", \"various\", \"vd\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"W\", \"wa\", \"was\", \"wasn\", \"wasnt\", \"way\", \"we\", \"wed\", \"welcome\", \"well\", \"well-b\", \"went\", \"were\", \"weren\", \"werent\", \"what\", \"whatever\", \"whats\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"whom\", \"whomever\", \"whos\", \"whose\", \"why\", \"wi\", \"widely\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"would\", \"wouldn\", \"wouldnt\", \"www\", \"x\", \"X\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"Y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"your\", \"youre\", \"yours\", \"yr\", \"ys\", \"yt\", \"z\", \"Z\", \"zero\", \"zi\", \"zz\"]\r\n",
    "dfStopWordsSorted = df.copy()\r\n",
    "\r\n",
    "dfStopWordsSorted.drop(labels=stopWords, axis=0, inplace=True, errors=\"ignore\")\r\n",
    "dfStopWordsSorted = dfStopWordsSorted.sort_values(by='Count', ascending=False)\r\n",
    "dfStopWordsSorted\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>curdie</th>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>princess</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irene</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>will</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melted</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>springs</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mossy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3715 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Count\n",
       "curdie      295\n",
       "princess    259\n",
       "irene       171\n",
       "will        164\n",
       "see         142\n",
       "...         ...\n",
       "beds          1\n",
       "melted        1\n",
       "springs       1\n",
       "mossy         1\n",
       "volume        1\n",
       "\n",
       "[3715 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "e.) `chapterDfList` contains the list of dataframes counting the words for each chapter. The process of creating this data frame is the same as parts a-d, except it is applied to each chapter instead of the entire text."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "chapterDfList = []\r\n",
    "ignoreChapterNum = False\r\n",
    "chapCount = 0\r\n",
    "\r\n",
    "with open('princessAndGoblin.txt', 'r') as file:\r\n",
    "    text = file.read()\r\n",
    "    text = text.split(\"CHAPTER\")\r\n",
    "    #pop a empty list cause splitting weirdness\r\n",
    "    text.pop(0)\r\n",
    "    for chapter in text:\r\n",
    "        chapterDict = {}\r\n",
    "        chapterWords = []\r\n",
    "        chapCount += 1\r\n",
    "\r\n",
    "        for word in chapter.split():\r\n",
    "            if word.isnumeric():\r\n",
    "                continue\r\n",
    "            addWordOnly(chapterWords, word)\r\n",
    "            \r\n",
    "        #add words in list\r\n",
    "        for word in chapterWords:   \r\n",
    "            if word.lower() in chapterDict:\r\n",
    "                chapterDict[word.lower()][0] += 1\r\n",
    "            else:\r\n",
    "                chapterDict[word.lower()] = [1]\r\n",
    "        \r\n",
    "        chapterDf = pd.DataFrame.from_dict(chapterDict, orient='index')\r\n",
    "        chapterDf.columns = ['Count']\r\n",
    "        chapterDf.drop(labels=stopWords, axis=0, inplace=True, errors=\"ignore\")\r\n",
    "        chapterDf = chapterDf.sort_values(by='Count', ascending=False)\r\n",
    "        chapterDfList.append(chapterDf)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.11 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "2028cae5e1ccfd73f96864fcab749a741bd0171c015975c3f420b043b6b34333"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}